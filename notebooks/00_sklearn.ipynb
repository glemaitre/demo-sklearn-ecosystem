{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667ed4fa",
   "metadata": {},
   "source": [
    "\n",
    "# What scikit-learn allows you to do?\n",
    "\n",
    "No better way than to show an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1470c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3534fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991599aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, data_test, target, target_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb479f1b",
   "metadata": {},
   "source": [
    "\n",
    "Craft a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "geo_columns = [\"Latitude\", \"Longitude\"]\n",
    "spline_columns = [\"MedInc\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (KMeans(n_clusters=10), geo_columns),\n",
    "    (make_pipeline(StandardScaler(), SplineTransformer()), spline_columns),\n",
    ")\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=True),\n",
    "    Ridge(),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8164c9",
   "metadata": {},
   "source": [
    "\n",
    "Evaluate the model via cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "cv_results = cross_validate(\n",
    "    model, data, target, cv=cv, return_estimator=True, return_train_score=True\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results[[\"train_score\", \"test_score\"]].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "for est, ax in zip_longest(cv_results[\"estimator\"], axs.ravel()):\n",
    "    if est is None:\n",
    "        ax.set_visible(False)\n",
    "        continue\n",
    "    PredictionErrorDisplay.from_estimator(\n",
    "        est, data_test, target_test, kind=\"actual_vs_predicted\", ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"R2 score: {est.score(data_test, target_test):.2f}\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_position((\"outward\", 10))\n",
    "    ax.spines[\"bottom\"].set_position((\"outward\", 10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b070c",
   "metadata": {},
   "source": [
    "\n",
    "Tune the hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26877fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (KMeans(n_clusters=10), geo_columns),\n",
    "    (make_pipeline(StandardScaler(), SplineTransformer()), spline_columns),\n",
    ")\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    PolynomialFeatures(degree=1, include_bias=False, interaction_only=True),\n",
    "    SelectKBest(k=30),\n",
    "    RidgeCV(alphas=np.logspace(-5, 5, num=50)),\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    \"columntransformer__kmeans__n_clusters\": randint(2, 30),\n",
    "    \"columntransformer__pipeline__splinetransformer__n_knots\": randint(2, 10),\n",
    "    \"polynomialfeatures__degree\": [1, 2],\n",
    "    \"selectkbest__k\": randint(50, 1000),\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions, cv=cv, n_iter=10, verbose=1_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "cv_results_path = Path(\"../data/00_search_cv.joblib\")\n",
    "\n",
    "# It is costly, let's reload from the disk if it exists\n",
    "if cv_results_path.exists():\n",
    "    cv_results = joblib.load(cv_results_path)\n",
    "else:\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        cv_results = cross_validate(\n",
    "            search, data, target, cv=cv, return_estimator=True, return_train_score=True\n",
    "        )\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    joblib.dump(cv_results, cv_results_path)\n",
    "cv_results[[\"train_score\", \"test_score\"]].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfafabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in cv_results[\"estimator\"]:\n",
    "    print(est.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4b4f0",
   "metadata": {},
   "source": [
    "\n",
    "Bonus point: you can dump the model and use it in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ea9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search.fit(data, target)\n",
    "# joblib.dump(search.best_estimator_, \"../models/00_my_production_model.joblib\")\n",
    "# prod_model = joblib.load(\"../models/00_my_production_model.joblib\")\n",
    "# prod_model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60854683",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusions\n",
    "\n",
    "### Strengths\n",
    "\n",
    "- Simple consistent API\n",
    "- A lot of building block to build and tune your predictive model\n",
    "- A lot of tools to evaluate your predictive model\n",
    "- A lot of tools to inspect your predictive model\n",
    "- Robust and fast implementation\n",
    "- Good documentation\n",
    "\n",
    "### Pitfalls\n",
    "\n",
    "**From the demo**\n",
    "- By nature, scikit-learn offers generic components\n",
    "- Know-how is extremely important\n",
    "  - No available baseline to start with\n",
    "  - Some syntax are convoluted\n",
    "  - Some choices to be made require expertise\n",
    "  - One can make methodological errors\n",
    "\n",
    "**What we did not show**\n",
    "- Data preprocessing is actually hard\n",
    "  - Data can come from different sources\n",
    "  - Transformations are not necessarily standardized\n",
    "- What happens once predictive models are in production\n",
    "  - Pickling and security\n",
    "  - Documentation\n",
    "  - Registry"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
