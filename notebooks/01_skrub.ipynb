{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d23fed",
   "metadata": {},
   "source": [
    "\n",
    "# `skrub`\n",
    "\n",
    "## Help in the exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_employee_salaries\n",
    "\n",
    "employee_salaries = fetch_employee_salaries()\n",
    "X, y = employee_salaries.X, employee_salaries.y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableReport\n",
    "\n",
    "table = TableReport(employee_salaries.employee_salaries)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ead32",
   "metadata": {},
   "source": [
    "\n",
    "## Help at preprocessing data\n",
    "\n",
    "`skrub` comes with a set of additional encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import DatetimeEncoder, ToDatetime\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "encoder = make_pipeline(ToDatetime(), DatetimeEncoder())\n",
    "encoder.fit_transform(X[\"date_first_hired\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cf757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import MinHashEncoder\n",
    "\n",
    "encoder = MinHashEncoder()\n",
    "encoder.fit_transform(X[\"employee_position_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0c7fa",
   "metadata": {},
   "source": [
    "\n",
    "`TableVectorizer` helps at reducing the boilerplate of `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d47c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableVectorizer\n",
    "\n",
    "vectorizer = TableVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb03e9b",
   "metadata": {},
   "source": [
    "\n",
    "## Help at getting a good baseline model\n",
    "\n",
    "`tabular_learner` to help at getting meaningful baselines quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import tabular_learner\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "model = tabular_learner(RidgeCV())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tabular_learner(\"regressor\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, X, y)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af0742",
   "metadata": {},
   "source": [
    "\n",
    "## Machine learning going back to the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a033fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_credit_fraud\n",
    "\n",
    "\n",
    "dataset = fetch_credit_fraud()\n",
    "TableReport(dataset.baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(dataset.products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865c769",
   "metadata": {},
   "source": [
    "\n",
    "Express data transformations for machine learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub\n",
    "\n",
    "products = skrub.var(\"products\", dataset.products)\n",
    "baskets = skrub.var(\"baskets\", dataset.baskets)\n",
    "basket_IDs = baskets[[\"ID\"]].skb.mark_as_X()\n",
    "fraud_flags = baskets[\"fraud_flag\"].skb.mark_as_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import selectors as s\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "vectorizer = skrub.TableVectorizer(high_cardinality=skrub.StringEncoder(), n_jobs=-1)\n",
    "predictor = ExtraTreesClassifier(n_jobs=-1)\n",
    "predictions = (\n",
    "    basket_IDs.merge(\n",
    "        products.skb.apply(vectorizer, cols=s.all() - \"basket_ID\")\n",
    "        .groupby(\"basket_ID\")\n",
    "        .agg(\"mean\")\n",
    "        .reset_index(),\n",
    "        left_on=\"ID\",\n",
    "        right_on=\"basket_ID\",\n",
    "    )\n",
    "    .drop(columns=[\"ID\", \"basket_ID\"])\n",
    "    .skb.apply(predictor, y=fraud_flags)\n",
    ")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b9367",
   "metadata": {},
   "source": [
    "\n",
    "Revisit the way to define hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241518f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = skrub.StringEncoder(\n",
    "    vectorizer=skrub.choose_from([\"tfidf\", \"hashing\"], name=\"vectorizer\"),\n",
    ")\n",
    "vectorizer = skrub.TableVectorizer(high_cardinality=encoder, n_jobs=-1)\n",
    "predictor = ExtraTreesClassifier(\n",
    "    max_leaf_nodes=skrub.choose_from([10, 30, 100], name=\"max_leaf_nodes\"),\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "search_path = Path(\"../data/01_search.joblib\")\n",
    "\n",
    "if search_path.exists():\n",
    "    search = joblib.load(search_path)\n",
    "else:\n",
    "    search = (\n",
    "        basket_IDs.merge(\n",
    "            products.skb.apply(vectorizer, cols=s.all() - \"basket_ID\")\n",
    "            .groupby(\"basket_ID\")\n",
    "            .agg(\"mean\")\n",
    "            .reset_index(),\n",
    "            left_on=\"ID\",\n",
    "            right_on=\"basket_ID\",\n",
    "        )\n",
    "        .drop(columns=[\"ID\", \"basket_ID\"])\n",
    "        .skb.apply(predictor, y=fraud_flags)\n",
    "    ).skb.get_randomized_search(fitted=True, scoring=\"roc_auc\", verbose=2)\n",
    "    joblib.dump(search, search_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e00784",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d6805",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusions\n",
    "\n",
    "**Vision**\n",
    "- Less wrangling, more machine learning\n",
    "- Bring the world of database closer to machine learning\n",
    "\n",
    "**Wrap-up**\n",
    "- Additional components to assemble, encode, and vectorize data\n",
    "- Reduce boilerplate code to get good baseline\n",
    "- Broader the scope of scikit-learn pipeline to the database world\n",
    "\n",
    "**Bold vision**\n",
    "- scikit-learn should be the machine learning toolbox with its numerical\n",
    "  optimization roots and expertise\n",
    "- skrub could be where the data preparation happen with integration with\n",
    "  dataframe-like libraries"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
