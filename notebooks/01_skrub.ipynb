{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f095b34",
   "metadata": {},
   "source": [
    "\n",
    "# `skrub`\n",
    "\n",
    "## Help in the exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572984ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_employee_salaries\n",
    "\n",
    "employee_salaries = fetch_employee_salaries()\n",
    "X, y = employee_salaries.X, employee_salaries.y\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd98940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableReport\n",
    "\n",
    "table = TableReport(employee_salaries.employee_salaries)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07257a",
   "metadata": {},
   "source": [
    "\n",
    "## Help at preprocessing data\n",
    "\n",
    "`skrub` comes with a set of additional encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3596af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import DatetimeEncoder, ToDatetime\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "encoder = make_pipeline(ToDatetime(), DatetimeEncoder())\n",
    "encoder.fit_transform(X[\"date_first_hired\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3810c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import MinHashEncoder\n",
    "\n",
    "encoder = MinHashEncoder()\n",
    "encoder.fit_transform(X[\"employee_position_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d39076",
   "metadata": {},
   "source": [
    "\n",
    "`TableVectorizer` helps at reducing the boilerplate of `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableVectorizer\n",
    "\n",
    "vectorizer = TableVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8751e70",
   "metadata": {},
   "source": [
    "\n",
    "## Help at getting a good baseline model\n",
    "\n",
    "`tabular_learner` to help at getting meaningful baselines quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ad76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import tabular_learner\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "model = tabular_learner(RidgeCV())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d031ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tabular_learner(\"regressor\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, X, y)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f08237",
   "metadata": {},
   "source": [
    "\n",
    "## Machine learning going back to the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_credit_fraud\n",
    "\n",
    "\n",
    "dataset = fetch_credit_fraud()\n",
    "TableReport(dataset.baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(dataset.products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8a2c3",
   "metadata": {},
   "source": [
    "\n",
    "Express data transformations for machine learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub\n",
    "\n",
    "products = skrub.var(\"products\", dataset.products)\n",
    "baskets = skrub.var(\"baskets\", dataset.baskets)\n",
    "basket_IDs = baskets[[\"ID\"]].skb.mark_as_X()\n",
    "fraud_flags = baskets[\"fraud_flag\"].skb.mark_as_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import selectors as s\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "vectorizer = skrub.TableVectorizer(high_cardinality=skrub.StringEncoder(), n_jobs=-1)\n",
    "predictor = ExtraTreesClassifier(n_jobs=-1)\n",
    "predictions = (\n",
    "    basket_IDs.merge(\n",
    "        products.skb.apply(vectorizer, cols=s.all() - \"basket_ID\")\n",
    "        .groupby(\"basket_ID\")\n",
    "        .agg(\"mean\")\n",
    "        .reset_index(),\n",
    "        left_on=\"ID\",\n",
    "        right_on=\"basket_ID\",\n",
    "    )\n",
    "    .drop(columns=[\"ID\", \"basket_ID\"])\n",
    "    .skb.apply(predictor, y=fraud_flags)\n",
    ")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a24d95",
   "metadata": {},
   "source": [
    "\n",
    "Revisit the way to define hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3186d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = skrub.StringEncoder(\n",
    "    vectorizer=skrub.choose_from([\"tfidf\", \"hashing\"], name=\"vectorizer\"),\n",
    ")\n",
    "vectorizer = skrub.TableVectorizer(high_cardinality=encoder, n_jobs=-1)\n",
    "predictor = ExtraTreesClassifier(\n",
    "    max_leaf_nodes=skrub.choose_from([10, 30, 100], name=\"max_leaf_nodes\"),\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "search_path = Path(\"../data/01_search.joblib\")\n",
    "\n",
    "if search_path.exists():\n",
    "    search = joblib.load(search_path)\n",
    "else:\n",
    "    search = (\n",
    "        basket_IDs.merge(\n",
    "            products.skb.apply(vectorizer, cols=s.all() - \"basket_ID\")\n",
    "            .groupby(\"basket_ID\")\n",
    "            .agg(\"mean\")\n",
    "            .reset_index(),\n",
    "            left_on=\"ID\",\n",
    "            right_on=\"basket_ID\",\n",
    "        )\n",
    "        .drop(columns=[\"ID\", \"basket_ID\"])\n",
    "        .skb.apply(predictor, y=fraud_flags)\n",
    "    ).skb.get_randomized_search(fitted=True, scoring=\"roc_auc\", verbose=2)\n",
    "    joblib.dump(search, search_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acff4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dffe5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b022d3",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusions\n",
    "\n",
    "**Vision**\n",
    "- Less wrangling, more machine learning\n",
    "- Bring the world of database closer to machine learning\n",
    "\n",
    "**Wrap-up**\n",
    "- Additional components to assemble, encode, and vectorize data\n",
    "- Reduce boilerplate code to get good baseline\n",
    "- Broader the scope of scikit-learn pipeline to the database world\n",
    "\n",
    "**Bold vision**\n",
    "- scikit-learn should be the machine learning toolbox with its numerical\n",
    "  optimization roots and expertise\n",
    "- skrub could be where the data preparation happen with integration with\n",
    "  dataframe-like libraries"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
